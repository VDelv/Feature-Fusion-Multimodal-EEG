{
 "cells": [
  {
   "cell_type": "raw",
   "id": "94614a73-2498-4ef6-a13f-9359923fbc29",
   "metadata": {},
   "source": [
    "Created by Victor Delvigne\n",
    "ISIA Lab, Faculty of Engineering University of Mons, Mons (Belgium)\n",
    "victor.delvigne@umons.ac.be\n",
    "Copyright (C) 2021 - UMons\n",
    "This library is free software; you can redistribute it and/or\n",
    "modify it under the terms of the GNU Lesser General Public\n",
    "License as published by the Free Software Foundation; either\n",
    "version 2.1 of the License, or (at your option) any later version.\n",
    "This library is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n",
    "Lesser General Public License for more details.\n",
    "You should have received a copy of the GNU Lesser General Public\n",
    "License along with this library; if not, write to the Free Software\n",
    "Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-soviet",
   "metadata": {},
   "source": [
    "# Single Modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "common-screening",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Feature_fusion/models.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcompact_bilinear_pooling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountSketch, CompactBilinearPooling\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n",
      "File \u001b[0;32m<frozen zipimport>:259\u001b[0m, in \u001b[0;36mload_module\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/trash/lib/python3.8/site-packages/pytorch_compact_bilinear_pooling-0.4.0-py3.8.egg/compact_bilinear_pooling/__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Function\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAttention(nn.Module):\n",
    "    def __init__(self, spatial_dep, emb_dim, feat_dim=5, eeg=False, pos=None, n_class=2):\n",
    "        super(MultiAttention, self ).__init__()\n",
    "        \n",
    "        if eeg:\n",
    "            self.spatial_attention = RegionRNN_DEAP(emb_dim//2, 1, feat_dim, f_dim=feat_dim)\n",
    "        else: \n",
    "            self.spatial_attention = SimpleRNN_DEAP(emb_dim, 1, feat_dim, f_dim=feat_dim)\n",
    "            \n",
    "        self.Classifier = nn.Sequential(\n",
    "            nn.Linear(emb_dim, 64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, n_class),\n",
    "            nn.Softmax(dim=1)\n",
    "            )\n",
    "    \n",
    "        self.Regressor = nn.Sequential(\n",
    "            nn.Linear(emb_dim, 64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 1)\n",
    "            )\n",
    "        \n",
    "        self.Discriminator = nn.Sequential(\n",
    "            GradientReversal(),\n",
    "            nn.Linear(emb_dim, 64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        b_size = x.shape[0]\n",
    "        \n",
    "        spatial_x = x.transpose(1,2)\n",
    "        feat = self.spatial_attention(spatial_x)\n",
    "        \n",
    "        return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-treaty",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Parameters'''\n",
    "batch_size = 64\n",
    "n_epoch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(feat, label, participant, path_results, training_info, n_class, is_eeg=False, pos=None):\n",
    "    EEG = EEGDataset(label=label, eeg=feat)\n",
    "    Tot = {}\n",
    "    session = np.load('dataset/seed_iv/session.npy')\n",
    "    for p in tqdm(np.unique(participant)):\n",
    "        idx = np.argwhere(participant==p).squeeze()\n",
    "        np.random.shuffle(idx)\n",
    "        #id_train = np.argwhere(participant!=p).squeeze()\n",
    "        #id_test = idx        \n",
    "        id_train = idx[:int(0.8*len(idx))]\n",
    "        id_test = idx[int(0.8*len(idx)):]\n",
    "        #id_train = np.argwhere(np.logical_and(participant==p, session<=16)).squeeze()\n",
    "        #id_test = np.argwhere(np.logical_and(participant==p, session>16)).squeeze()\n",
    "        np.random.shuffle(id_train)\n",
    "        np.random.shuffle(id_test)\n",
    "        Test = Subset(EEG, id_test)\n",
    "        Train = Subset(EEG, id_train)\n",
    "\n",
    "        Trainloader = DataLoader(Train, batch_size=batch_size, shuffle=False)\n",
    "        Testloader = DataLoader(Test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        n_chan = feat.shape[2]\n",
    "        f_dim = feat.shape[1]\n",
    "\n",
    "\n",
    "        net = MultiAttention(spatial_dep=n_chan, emb_dim=64, feat_dim=f_dim, eeg=is_eeg, pos=pos, n_class=n_class).cuda()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "        writer = SummaryWriter('runs/rnn_phy_'+str(np.random.randint(0, 1000)))\n",
    "\n",
    "        res = []\n",
    "        for epoch in range(n_epoch):\n",
    "\n",
    "            running_loss = 0.0\n",
    "            evaluation = []\n",
    "            t_cycle = iter(cycle(Testloader))\n",
    "            net.train()\n",
    "            for i, data in enumerate(Trainloader, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs_source, labels = data\n",
    "                del data\n",
    "\n",
    "                data = next(t_cycle)\n",
    "                inputs_test, _ = data\n",
    "                del data\n",
    "\n",
    "                domain = torch.cat([torch.ones(inputs_source.shape[0]),\n",
    "                                   torch.zeros(inputs_test.shape[0])]).cuda()\n",
    "                inputs = torch.cat([inputs_source, inputs_test])\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward + backward + optimize\n",
    "                feat_ = net(inputs.to(torch.float32).cuda())\n",
    "                domain_pred = net.Discriminator(feat_).squeeze()\n",
    "\n",
    "                loss = torch.nn.functional.binary_cross_entropy(domain_pred, domain)\n",
    "\n",
    "                outputs = net.Classifier(feat_[:inputs_source.shape[0]])\n",
    "\n",
    "                label_loss = torch.nn.functional.cross_entropy(outputs, labels.to(torch.long).cuda())\n",
    "                loss += label_loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                num_of_true = torch.sum(predicted.detach().cpu()==labels).numpy()\n",
    "                mean = num_of_true/labels.shape[0]\n",
    "                running_loss += label_loss.item()\n",
    "                evaluation.append(mean)\n",
    "            running_loss = running_loss/(i+1)\n",
    "            running_acc = sum(evaluation)/len(evaluation)\n",
    "\n",
    "            validation_loss = 0.0\n",
    "            validation_acc = 0.0\n",
    "            evaluation = []\n",
    "            net.eval()\n",
    "            for i, data in enumerate(Testloader, 0):\n",
    "                inputs, labels = data\n",
    "                del data\n",
    "                outputs = net(inputs.to(torch.float32).cuda())\n",
    "                outputs = net.Classifier(outputs)\n",
    "                loss = torch.nn.functional.cross_entropy(outputs, labels.cuda())\n",
    "                validation_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                num_of_true = torch.sum(predicted.detach().cpu()==labels).numpy()\n",
    "                evaluation.append(num_of_true/labels.shape[0])\n",
    "            validation_loss = validation_loss/(i+1)\n",
    "            validation_acc = sum(evaluation)/len(evaluation)\n",
    "\n",
    "            writer.add_scalar('Loss/Train', running_loss, epoch)\n",
    "            writer.add_scalar('Loss/Test', validation_loss, epoch)\n",
    "            writer.add_scalar('Acc/Train', running_acc, epoch)\n",
    "            writer.add_scalar('Acc/Test', validation_acc, epoch)\n",
    "            res.append((running_loss, running_acc, validation_loss, validation_acc))\n",
    "            #if epoch%5==4:\n",
    "            #    print('epoch %d \\t training loss: %.3f - training acc: %.3f \\t validation loss: %.3f - validation acc: %.3f'% (epoch+1, running_loss, running_acc, validation_loss, validation_acc))\n",
    "        Tot['participant_'+str(p)] = np.asarray(res)\n",
    "        np.save(os.path.join(path_results, training_info), Tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-comparison",
   "metadata": {},
   "source": [
    "## PhyDAA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572364d2-f959-42a4-92ca-7e582c37d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load File'''\n",
    "label = np.load('dataset/phydaa/label.npy').astype(int)\n",
    "n_class = len(np.unique(label))\n",
    "participant = np.load('dataset/phydaa/participant.npy')\n",
    "elec_pos = np.load('information/phydaa_eeg.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-grocery",
   "metadata": {},
   "source": [
    "### EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09622be7-3add-45f2-83ba-605b82d25277",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(feat=np.load('dataset/phydaa/feat_eeg.npy'), label=label, participant=participant, \n",
    "            path_results='res/ind/', training_info='eeg_phydaa_rnn_nodom', n_class=n_class, is_eeg=True, pos=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-snapshot",
   "metadata": {},
   "source": [
    "### Physiological"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50b2110-ec41-45ce-bea0-ad94054e9bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(feat=np.expand_dims(np.load('dataset/phydaa/feat_phy.npy'), 1), label=label, \n",
    "            participant=participant, path_results='res/ind/', training_info='feat_phydaa_rnn_nodom', n_class=n_class, is_eeg=False, pos=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-prospect",
   "metadata": {},
   "source": [
    "## SEED IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a51e6a-a5da-493d-b23d-60eaecc86e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load File'''\n",
    "label = np.load('dataset/seed_iv//label.npy').astype(int)\n",
    "n_class = len(np.unique(label))\n",
    "participant = np.load('dataset/seed_iv/participant.npy')\n",
    "elec_pos = np.load('information/seed_iv_eeg.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-cartoon",
   "metadata": {},
   "source": [
    "### EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cde1480-e3a7-4405-ac18-8c3b05192564",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(feat=np.load('dataset/seed_iv/feat_eeg.npy'), label=label, participant=participant, \n",
    "            path_results='res/dep/', training_info='eeg_seed_iv', n_class=n_class, is_eeg=True, pos=elec_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-dominant",
   "metadata": {},
   "source": [
    "### Physiological"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef7c007-66d5-4f1b-8b75-820d6fc14705",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(feat=np.expand_dims(np.load('dataset/seed_iv/feat_phy.npy'), 1), label=label, \n",
    "            participant=participant, path_results='res/dep/', training_info='feat_seed_iv', n_class=n_class, is_eeg=False, pos=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-affiliate",
   "metadata": {},
   "source": [
    "## DEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load File'''\n",
    "label = np.load('dataset/deap/label.npy') - 4.5\n",
    "n_class = 2 #len(np.unique(label))\n",
    "participant = np.load('dataset/deap/participant.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-portugal",
   "metadata": {},
   "source": [
    "### EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(feat=np.load('dataset/deap/feat_eeg.npy'), label=(label[:, 0]>0).astype(int), participant=participant, \n",
    "            path_results='res/ind/', training_info='eeg_deap_valence', n_class=n_class, is_eeg=True, pos=None)\n",
    "\n",
    "train_model(feat=np.load('dataset/deap/feat_eeg.npy'), label=(label[:, 1]>0).astype(int), participant=participant, \n",
    "            path_results='res/ind/', training_info='eeg_deap_arousal', n_class=n_class, is_eeg=True, pos=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-choir",
   "metadata": {},
   "source": [
    "### Physiological"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(feat=np.load('dataset/deap/feat_phy.npy'), label=(label[:, 0]>0).astype(int), participant=participant, \n",
    "            path_results='res/ind/', training_info='feat_deap_valence', n_class=n_class, is_eeg=False, pos=None)\n",
    "\n",
    "train_model(feat=np.load('dataset/deap/feat_phy.npy'), label=(label[:, 1]>0).astype(int), participant=participant, \n",
    "            path_results='res/ind/', training_info='feat_deap_arousal', n_class=n_class, is_eeg=False, pos=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
