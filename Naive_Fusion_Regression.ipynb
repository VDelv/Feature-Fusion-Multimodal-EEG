{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c17c57f2-315b-4920-ac03-4194404d138f",
   "metadata": {},
   "source": [
    "Created by Victor Delvigne\n",
    "ISIA Lab, Faculty of Engineering University of Mons, Mons (Belgium)\n",
    "victor.delvigne@umons.ac.be\n",
    "Copyright (C) 2021 - UMons\n",
    "This library is free software; you can redistribute it and/or\n",
    "modify it under the terms of the GNU Lesser General Public\n",
    "License as published by the Free Software Foundation; either\n",
    "version 2.1 of the License, or (at your option) any later version.\n",
    "This library is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n",
    "Lesser General Public License for more details.\n",
    "You should have received a copy of the GNU Lesser General Public\n",
    "License along with this library; if not, write to the Free Software\n",
    "Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-jacket",
   "metadata": {},
   "source": [
    "# Na√Øve fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from utils  import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiFusion(nn.Module):\n",
    "    def __init__(self, eeg_dim, eeg_emb_dim,pos, phy_dim, phy_emb_dim, phy_feat_dim, eeg_feat_dim=5, n_class=2):\n",
    "        super(MultiFusion, self ).__init__()\n",
    "        \n",
    "        self.eeg_attention = RegionRNN_VIG(eeg_emb_dim//2, 1, eeg_feat_dim, f_dim=eeg_feat_dim)\n",
    "        self.phy_attention = SimpleRNN(phy_emb_dim, 1, phy_feat_dim, f_dim=phy_feat_dim)\n",
    "        \n",
    "        self.Classifier = nn.Sequential(\n",
    "            nn.Linear(eeg_emb_dim, 64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, n_class),\n",
    "            nn.Softmax(dim=1)\n",
    "            )\n",
    "        \n",
    "        self.Regressor = nn.Sequential(\n",
    "            nn.Linear(eeg_emb_dim, 64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 1)\n",
    "            )\n",
    "        \n",
    "        self.Discriminator = nn.Sequential(\n",
    "            GradientReversal(),\n",
    "            nn.Linear(eeg_emb_dim, 64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "    def forward(self, x_eeg, x_phy):\n",
    "        b_size = x_eeg.shape[0]\n",
    "        \n",
    "        spatial_eeg = x_eeg.transpose(1,2)\n",
    "        feat_eeg = self.eeg_attention(spatial_eeg)\n",
    "        \n",
    "        spatial_phy = x_phy.transpose(1,2)\n",
    "        feat_phy = self.phy_attention(spatial_phy)\n",
    "        \n",
    "        feat = feat_eeg*feat_phy\n",
    "                \n",
    "        return feat\n",
    "\n",
    "class CatFusion(nn.Module):\n",
    "    def __init__(self, eeg_dim, eeg_emb_dim,pos, phy_dim, phy_emb_dim, phy_feat_dim, eeg_feat_dim=5, n_class=2):\n",
    "        super(CatFusion, self ).__init__()\n",
    "        \n",
    "        self.eeg_attention = RegionRNN_VIG(eeg_emb_dim//2, 1, eeg_feat_dim, f_dim=eeg_feat_dim)\n",
    "        self.phy_attention = SimpleRNN(phy_emb_dim, 1, phy_feat_dim, f_dim=phy_feat_dim)      \n",
    "\n",
    "        self.Classifier = nn.Sequential(\n",
    "            nn.Linear(eeg_emb_dim+phy_emb_dim, 64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, n_class),\n",
    "            nn.Softmax(dim=1)\n",
    "            )\n",
    "        \n",
    "        self.Regressor = nn.Sequential(\n",
    "            nn.Linear(eeg_emb_dim+phy_emb_dim, 64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 1)\n",
    "            )\n",
    "        \n",
    "        self.Discriminator = nn.Sequential(\n",
    "            GradientReversal(),\n",
    "            nn.Linear(eeg_emb_dim+phy_emb_dim, 64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        \n",
    "    def forward(self, x_eeg, x_phy):\n",
    "        b_size = x_eeg.shape[0]\n",
    "        \n",
    "        spatial_eeg = x_eeg.transpose(1,2)\n",
    "        feat_eeg = self.eeg_attention(spatial_eeg)\n",
    "        \n",
    "        spatial_phy = x_phy.transpose(1,2)\n",
    "        feat_phy = self.phy_attention(spatial_phy)\n",
    "        feat = torch.cat([feat_eeg,feat_phy], axis=1)\n",
    "                \n",
    "        return feat\n",
    "\n",
    "class BilFusion(nn.Module):\n",
    "    def __init__(self, eeg_dim, eeg_emb_dim,pos, phy_dim, phy_emb_dim, phy_feat_dim, eeg_feat_dim=5, n_class=2):\n",
    "        super(BilFusion, self ).__init__()\n",
    "        \n",
    "        self.eeg_attention = RegionRNN_VIG(eeg_emb_dim//2, 1, eeg_feat_dim, f_dim=eeg_feat_dim)\n",
    "        self.phy_attention = SimpleRNN(phy_emb_dim, 1, phy_feat_dim, f_dim=phy_feat_dim)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.mcb = CompactBilinearPooling(eeg_emb_dim, phy_emb_dim, eeg_emb_dim+phy_emb_dim).cuda()\n",
    "        else :\n",
    "            self.mcb = CompactBilinearPooling(eeg_emb_dim, phy_emb_dim, eeg_emb_dim+phy_emb_dim)\n",
    "\n",
    "        self.Classifier = nn.Sequential(\n",
    "            nn.Linear(eeg_emb_dim+phy_emb_dim, 64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, n_class),\n",
    "            nn.Softmax(dim=1)\n",
    "            )\n",
    "        \n",
    "        self.Regressor = nn.Sequential(\n",
    "            nn.Linear(eeg_emb_dim+phy_emb_dim, 64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 1)\n",
    "            )\n",
    "        \n",
    "        self.Discriminator = nn.Sequential(\n",
    "            GradientReversal(),\n",
    "            nn.Linear(eeg_emb_dim+phy_emb_dim, 64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "    def forward(self, x_eeg, x_phy):\n",
    "        b_size = x_eeg.shape[0]\n",
    "        \n",
    "        spatial_eeg = x_eeg.transpose(1,2)\n",
    "        feat_eeg = self.eeg_attention(spatial_eeg)\n",
    "        \n",
    "        spatial_phy = x_phy.transpose(1,2)\n",
    "        feat_phy = self.phy_attention(spatial_phy)\n",
    "        feat = self.mcb(feat_eeg, feat_phy)\n",
    "                \n",
    "        return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-diamond",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Parameters'''\n",
    "batch_size = 64\n",
    "n_epoch = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(feat_eeg, feat_phy, label, participant, path_results, training_info, n_class, pos, fusion):\n",
    "    EEG = EEGPhiDataset(label=label, eeg=feat_eeg, phi=feat_phy)\n",
    "    Tot = {}\n",
    "    for p in tqdm(np.unique(participant)):\n",
    "        \n",
    "        idx = np.argwhere(participant==p).squeeze()\n",
    "        np.random.shuffle(idx)\n",
    "        id_train = idx[:int(0.8*len(idx))]\n",
    "        id_test = idx[int(0.8*len(idx)):]\n",
    "        \n",
    "        Test = Subset(EEG, id_test)\n",
    "        #idx = np.argwhere(participant!=p).squeeze()\n",
    "        #np.random.shuffle(idx)\n",
    "        Train = Subset(EEG, id_train)\n",
    "        \n",
    "        Trainloader = DataLoader(Train, batch_size=batch_size, shuffle=False)\n",
    "        Testloader = DataLoader(Test, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        n_chan = feat_eeg.shape[2]\n",
    "        f_dim_eeg = feat_eeg.shape[1]\n",
    "        \n",
    "        phy_dim = feat_phy.shape[2]\n",
    "        f_dim_phy = feat_phy.shape[1]\n",
    "        \n",
    "        if fusion == 'cat':\n",
    "            net = CatFusion(eeg_dim=n_chan, eeg_emb_dim=64, eeg_feat_dim=f_dim_eeg, pos=pos, phy_dim=phy_dim, phy_emb_dim=64, phy_feat_dim=f_dim_phy, n_class=n_class).cuda()\n",
    "        elif fusion == 'mult':\n",
    "            net = MultiFusion(eeg_dim=n_chan, eeg_emb_dim=64, eeg_feat_dim=f_dim_eeg, pos=pos, phy_dim=phy_dim, phy_emb_dim=64, phy_feat_dim=f_dim_phy, n_class=n_class).cuda()\n",
    "        elif fusion == 'bil':\n",
    "            net = BilFusion(eeg_dim=n_chan, eeg_emb_dim=64, eeg_feat_dim=f_dim_eeg, pos=pos, phy_dim=phy_dim, phy_emb_dim=64, phy_feat_dim=f_dim_phy, n_class=n_class).cuda()\n",
    "            \n",
    "        optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
    "        \n",
    "        res = {}\n",
    "        pred = []\n",
    "        for epoch in range(n_epoch):     \n",
    "            \n",
    "            running_loss = []\n",
    "            \n",
    "            t_cycle = iter(cycle(Testloader))\n",
    "            for i, data in enumerate(Trainloader, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs_eeg_source, inputs_phy_source, labels = data\n",
    "                del data\n",
    "                \n",
    "                data = next(t_cycle)\n",
    "                inputs_eeg_test, inputs_phy_test, _ = data\n",
    "                del data\n",
    "                \n",
    "                domain = torch.cat([torch.ones(inputs_eeg_source.shape[0]),\n",
    "                                   torch.zeros(inputs_eeg_test.shape[0])]).cuda()\n",
    "                inputs_eeg = torch.cat([inputs_eeg_source, inputs_eeg_test])\n",
    "                inputs_phy = torch.cat([inputs_phy_source, inputs_phy_test])\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward + backward + optimize\n",
    "                #feat_ = net(inputs_eeg_source.to(torch.float32).cuda(), inputs_phy_source.to(torch.float32).cuda())\n",
    "                feat_ = net(inputs_eeg.to(torch.float32).cuda(), inputs_phy.to(torch.float32).cuda())\n",
    "                \n",
    "                domain_pred = net.Discriminator(feat_).squeeze()\n",
    "                \n",
    "                loss = torch.nn.functional.binary_cross_entropy(domain_pred, domain)\n",
    "                outputs = net.Regressor(feat_[:inputs_eeg_source.shape[0]])\n",
    "                \n",
    "\n",
    "                label_loss = torch.nn.functional.mse_loss(outputs.squeeze(), labels.to(torch.float).cuda())\n",
    "                \n",
    "                loss += label_loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss.append(label_loss.item())\n",
    "            \n",
    "            #running_loss = np.mean(running_loss)\n",
    "            #running_rmse = rmse(np.asarray(y_label), np.asarray(y_pred))\n",
    "            #running_corr = corr(np.asarray(y_label), np.asarray(y_pred))\n",
    "            \n",
    "            if epoch%10 == 9:\n",
    "                y_pred = []\n",
    "                y_label = []\n",
    "                validation_loss = []\n",
    "                for i, data in enumerate(Testloader, 0):\n",
    "                    inputs_eeg, inputs_phy, labels = data\n",
    "                    del data\n",
    "                    feat_ = net(inputs_eeg.to(torch.float32).cuda(), inputs_phy.to(torch.float32).cuda())\n",
    "                    outputs = net.Regressor(feat_)\n",
    "                    y_pred.extend(outputs.squeeze().detach().cpu().tolist())\n",
    "                    y_label.extend(labels.tolist())\n",
    "\n",
    "                    loss = torch.nn.functional.mse_loss(outputs.squeeze(), labels.to(torch.float).cuda())\n",
    "                    validation_loss.append(loss.item())\n",
    "\n",
    "                pred.append(y_pred)\n",
    "        res['pred'] = np.asarray(pred)\n",
    "        res['test'] = np.asarray(y_label)\n",
    "        Tot['participant_'+str(p)] = np.asarray(res)\n",
    "        np.save(os.path.join(path_results, training_info), Tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-artwork",
   "metadata": {},
   "source": [
    "## SEED VIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load File'''\n",
    "label = np.load('dataset/seed_vig/label.npy')\n",
    "n_class = len(np.unique(label))\n",
    "participant = np.load('dataset/seed_vig/participant.npy')\n",
    "elec_pos = np.load('information/seed_vig_eeg.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-honey",
   "metadata": {},
   "source": [
    "### Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(feat_eeg=np.load('dataset/seed_vig/feat_eeg.npy'), feat_phy=np.expand_dims(np.load('dataset/seed_iv/feat_phy.npy'),1), label=label, \n",
    "            participant=participant, path_results='res/', training_info='seed_vig_mult', n_class=n_class, pos=elec_pos, fusion='mult')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-champagne",
   "metadata": {},
   "source": [
    "### Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(feat_eeg=np.load('dataset/seed_vig/feat_eeg.npy'), feat_phy=np.expand_dims(np.load('dataset/seed_iv/feat_phy.npy'),1), label=label, \n",
    "            participant=participant, path_results='res/', training_info='seed_vig_cat', n_class=n_class, pos=elec_pos, fusion='cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-utility",
   "metadata": {},
   "source": [
    "### Compact Bilinear Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(feat_eeg=np.load('dataset/seed_vig/feat_eeg.npy'), feat_phy=np.expand_dims(np.load('dataset/seed_iv/feat_phy.npy'),1), label=label, \n",
    "            participant=participant, path_results='res/', training_info='seed_vig_bil', n_class=n_class, pos=elec_pos, fusion='bil')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
